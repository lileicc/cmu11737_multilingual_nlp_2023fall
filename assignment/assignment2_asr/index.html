<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta>
    <meta>
    <meta>
    <link rel="stylesheet" type="text/css" href="../../origo.css"
      media="all">
    <meta name="author" content="Lei Li">
    <title>11737 Multilingual NLP Assignment 2</title>
  </head>
  <body>
    <header>
      <h1>Assignment 2: Multilingual Speech Recognition</h1>
      <!-- <p>Due Date: [Insert Due Date]</p> --> </header>
    <section id="introduction">
      <h2>Introduction</h2>
      <p>By completing this assignment you will be able develop an ASR
        system for any language. In this assignment, students are given
        the freedom to choose between two popular automatic speech
        recognition (ASR) frameworks: <code>espnet</code> and <code>fairseq</code>.
        The assignment focuses on two sub-tasks to evaluate the
        performance of these frameworks on the two recommended
        languages, <code>Guarani </code> and <code>Quechua</code> .
        You can find the <a
          href="https://commonvoice.mozilla.org/en/datasets">datasets</a>
        here.Additional data can be found <a moz-do-not-send="true"
          href="http://festvox.org/cmu_wilderness/">here</a>. <br>
      </p>
    </section>
    <section id="sub-task-1">
      <h2>Sub-Task 1: Individual ASR Models</h2>
      <p> For Sub-Task 1, students are required to create working ASR
        models using their chosen framework for Guarani. The primary
        objective is to build accurate ASR models and report the
        corresponding error rates. ASR for Quechua is optional. <br>
      </p>
    </section>
    <section id="sub-task-2">
      <h2>Sub-Task 2: Multi-Task, Multilingual Joint Training</h2>
      <p> In Sub-Task 2, students will explore advanced techniques by
        implementing multi-task, multilingual joint training, and using
        pre-trained models such as XLSR/Wav2vec2. This sub-task also
        focuses on the two recommended languages, Quechua and Guarani,
        and requires reporting the Word Error Rate (WER) for the trained
        models.Quechua is optional. Completing both tasks for Quechua
        will receive 20pts bonus. <br>
      </p>
    </section>
    <section id="assignment-guidelines">
      <h2>DL Frameworks<br>
      </h2>
      <ol>
      </ol>
      <strong>Choice of Framework:</strong> Students are encouraged to
      select either <a moz-do-not-send="true"
        href="https://github.com/espnet/espnet"><code>espnet</code></a>
      or <a moz-do-not-send="true"
        href="https://github.com/facebookresearch/fairseq"><code>fairseq</code></a>
      as their framework for this assignment.
      <ol>
        <!-- Add more assignment guidelines as needed -->
      </ol>
    </section>
    <section id="espnet-experiments">
      <h2>Experiments with ESPnet</h2>
      <p> If you choose to work with ESPnet, you have the opportunity to
        explore various experiments and extend your ASR knowledge. Below
        are some recommended experiments you can undertake: </p>
      <h3>Running the Base Experiment</h3>
      <p> The base code for this experiment is provided through a Google
        Colab notebook that can be accessed <a
href="https://colab.research.google.com/drive/176kej2U3j0VabwGzoHwJbYNvE9FrzSTj">here</a>.
        Your first task is to run the entire notebook from start to end.
        If you plan to conduct further experiments outside of Google
        Colab, we recommend saving it by creating a copy on your GitHub
        using "File -&gt; Save a copy on Github." </p>
      <h3>Running Another Non-English Recipe</h3>
      <p> You need to run an existing recipe in ESPnet for Guarani and
        Quechua (optional). The list of available reference recipes is <a
href="https://github.com/espnet/espnet/blob/master/egs2/README.md">available



          here</a>. Your goal is to modify the recipe and run it for the
        two languages mentioned. </p>
      <h3>Train a Speech Recognition System on a New Dataset</h3>
      <ol>
        <li>Following Stage 1, implement a bash script (local/data.sh)
          that includes:
          <ul>
            <li>Download the dataset</li>
            <li>Split the dataset into train / dev / test</li>
            <li>Perform text normalization, e.g., removing punctuation,
              unifying letter case, etc.</li>
            <li>Prepare the data in Kaldi style</li>
          </ul>
        </li>
        <li>Following Stage 2-4, do speed perturbation if necessary and
          dump the audio file.</li>
        <li>Prepare the tokenization model as in Stage 5.</li>
        <li>Train the language model (LM) following Stages 6 - 9.</li>
        <li>Train the end-to-end speech recognition model (E2E-ASR),
          following Stages 10 - 11.</li>
        <li>Decoding and scoring the dev and test sets with your system
          (LM + E2E-ASR), following Stages 12-13.</li>
      </ol>
      <p> These experiments will provide you with a comprehensive
        understanding of ASR and ESPnet's capabilities. </p>
    </section>
    <section id="fairseq-experiments">
      <h2>Experiments with fairseq</h2>
      <p>Please follow the following steps if you choose fairseq.<br>
      </p>
      <h3>Running the Base Experiment</h3>
      <p> Start by running the base ASR experiment provided in Fairseq.
        Follow the instructions in the official documentation to run the
        experiment on your chosen dataset. Carefully review and
        understand the configuration options, data preprocessing, and
        model training steps. Here's a reference <a
href="https://github.com/facebookresearch/fairseq/blob/main/examples/speech_to_text/docs/librispeech_example.md">
          git page </a> for the same. Here's a reference <a
href="https://colab.research.google.com/drive/1ujVxdcltog1OWQPn-Q_mHuruAHEjADYM#scrollTo=Ugv3lWAKf8XJ">
          colab notebook </a> for the same. </p>
      <h3>Changing the Preprocessing File</h3>
      <p> Fairseq, by default, includes a preprocessing file tailored
        for English datasets such as LibriSpeech. However, for this
        assignment, you will need to modify the preprocessing file to
        incorporate datasets from CommonVoice for the languages Quechua
        and Guarani. Follow these steps to make the necessary changes: </p>
      <ol>
        <li>Locate the Fairseq preprocessing file for data preparation.
          The path for this file in fairseq repo is typically named
          something like <code>examples/speech_to_text/prep_librispeech_data.py</code>.</li>
        <li>Open the preprocessing file using a text editor or
          integrated development environment (IDE).</li>
        <li>Identify the sections of the code that pertain to data
          loading, preprocessing, and tokenization. These sections are
          responsible for handling input data and transforming it into a
          format suitable for training ASR models.</li>
        <li>Within the preprocessing code, look for configurations
          related to data paths, data formats, and tokenization. You
          will need to update these configurations to specify the paths
          to the Quechua and Guarani datasets from CommonVoice.</li>
        <li>Ensure that you adapt the preprocessing steps to handle the
          specific characteristics of the Quechua and Guarani datasets.
          This may include text normalization, language-specific
          tokenization, and any other necessary data transformations.</li>
        <li>Test the modified preprocessing code by running it on the
          Quechua and Guarani datasets. Verify that the data is loaded,
          preprocessed, and tokenized correctly.</li>
        <li>Document any changes you make to the preprocessing file,
          including dataset paths, modifications to data loading
          functions, and any additional preprocessing steps. This
          documentation will be important for reproducibility and
          reporting in your assignment.</li>
      </ol>
      <p> Modifying the preprocessing file allows you to adapt Fairseq
        to handle non-English datasets and ensures that your ASR system
        can work effectively with the Quechua and Guarani datasets from
        CommonVoice. Remember to test and validate your changes
        thoroughly before proceeding with model training. </p>
      <h3>Customize Model Architecture</h3>
      <p> One of the strengths of Fairseq is its flexibility in
        customizing model architectures. You can experiment with
        different neural network architectures, such as LSTM,
        Transformer, Conformer, to improve ASR performance. Keep track
        of the changes you make and document the impact on recognition
        accuracy.<br>
      </p>
      <h3>Augmenting Training Objectives</h3>
      <p>You may explore CTC combined with LM (RNN transducer), joint
        training with multiple languages, and pre-training with
        additional data. <br>
      </p>
      <!-- <h3>Exploring Data Augmentation</h3>
    <p>
        Investigate data augmentation techniques to enhance the robustness of your ASR system. You can apply methods like speed perturbation, volume variation, and noise injection to the training data. Assess how these techniques affect the model's performance and report your findings.
    </p>
    
    <h3>Multi-Lingual ASR</h3>
    <p>
        Extend your experiment to support multi-lingual ASR by training on multiple languages. You can explore transfer learning and multi-task learning approaches to improve recognition accuracy across different languages. Provide insights into the challenges and benefits of multi-lingual ASR.
    </p> -->
      <h3>Advanced Decoding Techniques</h3>
      <p> Investigate advanced decoding techniques such as beam search,
        shallow fusion, and subword units. Compare the results of
        different decoding strategies and analyze their impact on ASR
        accuracy. </p>
      <p> These experiments with Fairseq will enable you to delve deeper
        into ASR research and gain valuable insights into customizing
        and optimizing ASR systems. </p>
    </section>
    <section id="grading">
      <h2>Grading</h2>
      <p> Your assignment for this project will be assessed as follows:
      </p>
      <ol>
        <li> <strong>Report Submission:</strong> We request that you
          submit a report for Assignment 2, which should be
          approximately 2 pages in length. Your report should include
          details of the implemented models, methodologies, and the
          results obtained in Sub-Task 1 and Sub-Task 2. </li>
        <li> <strong>Leaderboard Competition:</strong> We do not
          require participation in a leaderboard competition. The focus
          of this assignment is on individual effort and learning,
          rather than competition. </li>
        <li> <strong>Assessment of Effort:</strong> As long as you
          complete both Sub-Task 1 and Sub-Task 2 with reasonable
          effort, you will receive full credit for this assignment. The
          emphasis is on your learning and the application of ASR
          techniques rather than achieving specific performance metrics.
          <br>
        </li>
      </ol>
      <p> We encourage you to take this assignment as an opportunity to
        explore, learn, and experiment with ASR frameworks. If you have
        any questions or need clarifications, please don't hesitate to
        reach out to the course instructor or teaching assistant. </p>
    </section>
    <section id="conclusion">
      <h2>Goal</h2>
      <p> This assignment provides an opportunity for students to gain
        hands-on experience in automatic speech recognition using
        popular frameworks. The flexibility to choose between <code>espnet</code>
        and <code>fairseq</code> allows students to explore different
        approaches to ASR in the context of the languages Quechua and
        Guarani. Sub-Task 1 and Sub-Task 2 offer a comprehensive
        evaluation of ASR model performance. The primary goal is for
        students to enhance their understanding of ASR techniques and
        their practical application. </p>
      <p> For any questions or clarifications, please feel free to reach
        out to the course instructor or teaching assistant. Good luck
        with your assignment! </p>
    </section>
  </body>
</html>
